---
title: "Joint Entropy"
author: "iw"
date: "3 de noviembre de 2019"
output: html_document
---

## Identity

The entropy of two random variables can be expressed like the first plus the second conditionated to the first (S. Ross, 1997). In this case we have $d$ age at death and $\pi$ prevalence.
$$H(d,\pi) =  H(d) + H_d(\pi)$$

Being $H_d(\pi)$ the weigthed sum of prevalence entropy:

$$H(d,\pi) = H(d) + \sum_{i=0}^{x}d_i H(\pi,0-i)$$

¡¡¡If $d$ and $\pi$ are independent!!! then: 

$$H(d,\pi) =  H(d) + H(\pi)$$

## Toy example

```{r}

# two scenarios
pi1 = matrix(c(.1,NA,NA,
               .1,.1,NA,
               .1,.1,.1),3,3,T)
pi2 = matrix(c(.3,NA,NA,
               0,.2,NA,
               0,0,.1),3,3,T)

d = c(.2,.3,.5)
Hd = sum(-log(d)*d)
Hpi1_d = d[1] * sum(-log(pi1[1,])*pi1[1,], na.rm = T) +
        d[2] * sum(-log(pi1[2,])*pi1[2,], na.rm = T) +
        d[3] * sum(-log(pi1[2,])*pi1[2,], na.rm = T)
Hpi2_d = d[1] * sum(-log(pi2[1,])*pi2[1,], na.rm = T) +
        d[2] * sum(-log(pi2[2,])*pi2[2,], na.rm = T) +
        d[3] * sum(-log(pi2[2,])*pi2[2,], na.rm = T)
H1 = Hd + Hpi1_d
H2 = Hd + Hpi2_d
H1; H2

```

